{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e06c7fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52345bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/processed/train_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cd31fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('TARGET', axis=1)\n",
    "y = df['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c91d15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT (Stratified to keep the imbalance ratio)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65ef092d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imbalance Ratio: 11.39\n"
     ]
    }
   ],
   "source": [
    "ratio = float(np.sum(y == 0)) / np.sum(y == 1)\n",
    "print(f\"Imbalance Ratio: {ratio:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ca7610",
   "metadata": {},
   "source": [
    "DEFINE THE PARAMETER GRID\n",
    "\n",
    "This is the \"Menu\" the computer can choose from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1fff977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter Grid Set.\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    # How deep can each tree go?\n",
    "    # Deeper = Smarter but might overthink (overfit). Shallower = Simpler.\n",
    "    'max_depth': [3, 4, 5, 6, 8, 10],\n",
    "\n",
    "    # How fast should it learn?\n",
    "    # Lower number = Slow and careful learning (usually better but slower).\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "\n",
    "    # How many trees?\n",
    "    # More trees = More \"opinions\", but takes longer.\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "\n",
    "    # Subsample: What % of data does each tree see?\n",
    "    # If 0.8, each tree only sees 80% of data. This prevents memorization.\n",
    "    'subsample': [0.7, 0.8, 0.9, 1.0],\n",
    "\n",
    "    # Colsample: What % of columns (features) does each tree see?\n",
    "    # If 0.8, each tree only sees 80% of features. Good for robustness.\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "\n",
    "    # Scale Pos Weight: We test our calculated ratio, and maybe a bit higher/lower\n",
    "    'scale_pos_weight': [ratio, ratio * 1.2, ratio * 0.8] \n",
    "}\n",
    "\n",
    "print(\"Parameter Grid Set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808ad37d",
   "metadata": {},
   "source": [
    "Run the Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580f1c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_clf = xgb.XGBClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "# random_search = RandomizedSearchCV(\n",
    "#     estimator=xgb_clf, \n",
    "#     param_distributions=param_grid, \n",
    "#     n_iter=20,           # Try 20 random combinations (Change to 50 if you have time)\n",
    "#     scoring='roc_auc',   # Optimize for AUC, not Accuracy\n",
    "#     n_jobs=-1,           # Use all CPU cores\n",
    "#     cv=3,                # 3-Fold Cross Validation\n",
    "#     verbose=3,           # Show us progress logs\n",
    "#     random_state=42\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da66654d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # START TUNING\n",
    "# print(\"Starting Hyperparameter Tuning... (This may take a while)\")\n",
    "# random_search.fit(X_train, y_train)\n",
    "\n",
    "# print(\"\\nDONE!\")\n",
    "# print(f\"Best Score (AUC): {random_search.best_score_:.4f}\")\n",
    "# print(\"Best Parameters:\", random_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7747c7da",
   "metadata": {},
   "source": [
    "SETUP THE SEARCH (SAFE MODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cdeaf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_jobs=1 here prevents the \"Fork Bomb\". \n",
    "# It runs models one-by-one, so your RAM stays safe.\n",
    "xgb_clf = xgb.XGBClassifier(random_state=42, n_jobs=-1) # Model uses all cores\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_clf, \n",
    "    param_distributions=param_grid, \n",
    "    n_iter=50,           # Reduced from 20 to 15 to be safe/faster\n",
    "    scoring='roc_auc', \n",
    "    n_jobs=1,            # <--- THE CRITICAL FIX (Process 1 model at a time)\n",
    "    cv=3, \n",
    "    verbose=1,           # Less noise in the logs\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1b5220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Hyperparameter Tuning (Safe Mode)...\n",
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n",
      "\n",
      "DONE!\n",
      "Best Score (AUC): 0.7617\n",
      "Best Parameters: {'subsample': 1.0, 'scale_pos_weight': np.float64(11.387150050352467), 'n_estimators': 500, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.8}\n"
     ]
    }
   ],
   "source": [
    "# # START TUNING\n",
    "# print(\"Starting Hyperparameter Tuning (Safe Mode)...\")\n",
    "# random_search.fit(X_train, y_train)\n",
    "\n",
    "# print(\"\\nDONE!\")\n",
    "# print(f\"Best Score (AUC): {random_search.best_score_:.4f}\")\n",
    "# print(\"Best Parameters:\", random_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80af4be",
   "metadata": {},
   "source": [
    "15 iter\n",
    "\n",
    "Starting Hyperparameter Tuning (Safe Mode)...\n",
    "\n",
    "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n",
    "\n",
    "DONE!\n",
    "\n",
    "Best Score (AUC): 0.7617\n",
    "\n",
    "Best Parameters: {'subsample': 1.0, 'scale_pos_weight': np.float64(11.387150050352467), 'n_estimators': 500, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "787c8174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Hyperparameter Tuning (Safe Mode)...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "\n",
      "DONE!\n",
      "Best Score (AUC): 0.7617\n",
      "Best Parameters: {'subsample': 1.0, 'scale_pos_weight': np.float64(11.387150050352467), 'n_estimators': 500, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.8}\n"
     ]
    }
   ],
   "source": [
    "# START TUNING\n",
    "print(\"Starting Hyperparameter Tuning (Safe Mode)...\")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nDONE!\")\n",
    "print(f\"Best Score (AUC): {random_search.best_score_:.4f}\")\n",
    "print(\"Best Parameters:\", random_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed02227",
   "metadata": {},
   "source": [
    "# LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e5deb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names cleaned!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# 1. CLEAN COLUMN NAMES\n",
    "# We use Regex to replace any character that is NOT a letter or number with '_'\n",
    "clean_columns = [re.sub(r'[^\\w]', '_', col) for col in X_train.columns]\n",
    "\n",
    "# Apply to both Train and Test\n",
    "X_train.columns = clean_columns\n",
    "X_test.columns = clean_columns\n",
    "\n",
    "print(\"Column names cleaned!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "430853cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86f93695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP THE CLASSIFIER\n",
    "# We use the sklearn API (LGBMClassifier) because it plays nice with RandomizedSearchCV\n",
    "lgb_clf = lgb.LGBMClassifier(\n",
    "    objective='binary',\n",
    "    metric='auc',\n",
    "    is_unbalance=True,  # Handles the imbalance automatically\n",
    "    n_jobs=-1,\n",
    "    verbosity=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5287d632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE THE GRID\n",
    "# These are the most important knobs for LightGBM\n",
    "param_dist = {\n",
    "    # How complex can the tree be? (31 is standard, 50 is complex, 20 is simple)\n",
    "    'num_leaves': [20, 31, 50, 70], \n",
    "    \n",
    "    # How fast to learn?\n",
    "    'learning_rate': [0.01, 0.03, 0.05, 0.1],\n",
    "    \n",
    "    # How many trees?\n",
    "    'n_estimators': [200, 500, 1000],\n",
    "    \n",
    "    # Minimum data in one leaf (prevents overfitting)\n",
    "    'min_child_samples': [20, 50, 100],\n",
    "    \n",
    "    # Randomly select features/rows to make it robust\n",
    "    'subsample': [0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9, 1.0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d531561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP SEARCH\n",
    "random_search_lgbm = RandomizedSearchCV(\n",
    "    estimator=lgb_clf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,           # Test 20 combinations\n",
    "    scoring='roc_auc',\n",
    "    cv=3,                # 3-Fold Cross Validation\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=1             # Safe mode to prevent crashing\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb28b091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning LightGBM Champion...\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "\n",
      "DONE!\n",
      "Best LightGBM Score: 0.7631\n",
      "Best Parameters: {'subsample': 0.9, 'num_leaves': 31, 'n_estimators': 1000, 'min_child_samples': 50, 'learning_rate': 0.01, 'colsample_bytree': 0.9}\n"
     ]
    }
   ],
   "source": [
    "# RUN TUNING\n",
    "print(\"Tuning LightGBM Champion...\")\n",
    "# Make sure X_train still has the \"Clean Names\" from the previous step!\n",
    "random_search_lgbm.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nDONE!\")\n",
    "print(f\"Best LightGBM Score: {random_search_lgbm.best_score_:.4f}\")\n",
    "print(\"Best Parameters:\", random_search_lgbm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7661d840",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
